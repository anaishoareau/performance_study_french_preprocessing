{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test de performance du FrenchPreprocessing (StanfordPOSTagger vs CamemBERT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Objectif :**\n",
    "\n",
    "Etudier les performances de FrenchPreprocessing (avec deux taggers différents : StanfordPOSTagger et modèle CamemBERT) sur un dataset labélisé et les comparer à celles de TreeTagger.\n",
    "\n",
    "2. **Corpus utilisé :**\n",
    "    - Deep sequoia (version 9.1) : https://gitlab.inria.fr/sequoia/deep-sequoia/-/tree/master/tags/sequoia-9.1\n",
    "    - README deep Sequoia : https://gitlab.inria.fr/sequoia/deep-sequoia/-/blob/master/tags/sequoia-9.1/README-distrib.md\n",
    "    - Fichier utilisé dans l'étude : https://gitlab.inria.fr/sequoia/deep-sequoia/-/blob/master/tags/sequoia-9.1/sequoia.deep.conll  \n",
    "    \n",
    " \n",
    "3. **Fichers d'exécution pour l'étude :**\n",
    "\n",
    "    - creation_csv_sequoia.py : Permet de créer un dataset pour l'étude à partir des données du corpus Sequoia dans le fichier sequoia.conll\n",
    "    - labelisation_frenchpreprocessing-stanford.py : Réalise la lemmatisation des données brutes de sequoia.csv avec le FrenchPreprocessing (StanfordPOSTagger)\n",
    "    - labelisation_frenchpreprocessing-camemBERT.py : Réalise la lemmatisation des données brutes de sequoia.csv avec le FrenchPreprocessing (camemBERT)\n",
    "    - labelisation_treetagger.py : Réalise la lemmatisation des données brutes de sequoia.csv avec TreeTagger\n",
    "    \n",
    "    \n",
    "4. **Aide à l'installation :**\n",
    "\n",
    "\n",
    "* Pour installer TreeTagger à utiliser avec Python :\n",
    "\n",
    "    - Installer le wrapper python : https://pypi.org/project/treetaggerwrapper/ \n",
    "    - Télécharger TreeTagger et ajouter à /lib le fichier nécessaire pour le fonctionnement du wrapper : https://www.cis.uni-muenchen.de/~schmid/tools/TreeTagger/\n",
    "    - Tagset de TreeTagger : https://www.cis.uni-muenchen.de/~schmid/tools/TreeTagger/data/french-tagset.html\n",
    "\n",
    "\n",
    "* Pour installer les FrenchPreprocessing :\n",
    "\n",
    "    - Installation depuis github (version camemBERT) : https://github.com/anaishoareau/french_preprocessing   \n",
    "    - Installation depuis github (version StanfordPOSTagger) : https://github.com/anaishoareau/french_preprocessing-stanfordpostagger  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Imports\" data-toc-modified-id=\"Imports-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Imports</a></span></li><li><span><a href=\"#Chargement-du-dataset\" data-toc-modified-id=\"Chargement-du-dataset-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Chargement du dataset</a></span></li><li><span><a href=\"#Réduction-du-dataset\" data-toc-modified-id=\"Réduction-du-dataset-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Réduction du dataset</a></span></li><li><span><a href=\"#Exemple-de-lemmatisation\" data-toc-modified-id=\"Exemple-de-lemmatisation-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Exemple de lemmatisation</a></span></li><li><span><a href=\"#Performance-de-la-lemmatisation\" data-toc-modified-id=\"Performance-de-la-lemmatisation-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Performance de la lemmatisation</a></span><ul class=\"toc-item\"><li><span><a href=\"#Récupération-des-doublets-(mot,lemme)-labélisés\" data-toc-modified-id=\"Récupération-des-doublets-(mot,lemme)-labélisés-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Récupération des doublets (mot,lemme) labélisés</a></span></li><li><span><a href=\"#Calcul-du-nombre-de-doublets-(mot,lemme)-identiques\" data-toc-modified-id=\"Calcul-du-nombre-de-doublets-(mot,lemme)-identiques-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>Calcul du nombre de doublets (mot,lemme) identiques</a></span></li><li><span><a href=\"#Affichage-des-pourcentages\" data-toc-modified-id=\"Affichage-des-pourcentages-5.3\"><span class=\"toc-item-num\">5.3&nbsp;&nbsp;</span>Affichage des pourcentages</a></span></li></ul></li><li><span><a href=\"#Conclusion\" data-toc-modified-id=\"Conclusion-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Conclusion</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement du dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/sequoia.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Conversion du texte des colonnes \"sequoia\", \"frenchpreprocessing\", \"treetagger\" en objets list\n",
    "df['sequoia'] = df['sequoia'].map(lambda x: list(eval(x)))\n",
    "df['frenchpreprocessing_stanford'] = df['frenchpreprocessing_stanford'].map(lambda x: list(eval(x)))\n",
    "df['frenchpreprocessing_camemBERT'] = df['frenchpreprocessing_camemBERT'].map(lambda x: list(eval(x)))\n",
    "df['treetagger'] = df['treetagger'].map(lambda x: list(eval(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppresion des majuscules dans les lemmes (non vecteur de sens dans la lemmatisation)\n",
    "def lemma_maj_to_min(x):\n",
    "    l = []\n",
    "    for e in x:\n",
    "        if len(e)==3:\n",
    "            l.append((e[0], e[1], e[2].lower()))\n",
    "        else:\n",
    "            l.append((e[0], e[1].lower()))   \n",
    "    return l\n",
    "\n",
    "df['sequoia'] = df['sequoia'].map(lambda x: lemma_maj_to_min(x))\n",
    "df['frenchpreprocessing_stanford'] = df['frenchpreprocessing_stanford'].map(lambda x: lemma_maj_to_min(x))\n",
    "df['frenchpreprocessing_camemBERT'] = df['frenchpreprocessing_camemBERT'].map(lambda x: lemma_maj_to_min(x))\n",
    "df['treetagger'] = df['treetagger'].map(lambda x: lemma_maj_to_min(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Colonne comptant le nombre de tokens proposés par sequoia\n",
    "df['sequoia_nb_tokens'] = df['sequoia'].map(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent_id</th>\n",
       "      <th>sent</th>\n",
       "      <th>sequoia</th>\n",
       "      <th>treetagger</th>\n",
       "      <th>frenchpreprocessing_camemBERT</th>\n",
       "      <th>frenchpreprocessing_stanford</th>\n",
       "      <th>sequoia_nb_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>annodis.er_00001</td>\n",
       "      <td>Gutenberg</td>\n",
       "      <td>[(Gutenberg, npp, gutenberg)]</td>\n",
       "      <td>[(Gutenberg, gutenberg)]</td>\n",
       "      <td>[(Gutenberg, npp, gutenberg)]</td>\n",
       "      <td>[(Gutenberg, npp, gutenberg)]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>annodis.er_00002</td>\n",
       "      <td>Cette exposition nous apprend que dès le XIIe ...</td>\n",
       "      <td>[(Cette, det, ce), (exposition, nc, exposition...</td>\n",
       "      <td>[(Cette, ce), (exposition, exposition), (nous,...</td>\n",
       "      <td>[(Cette, det, ce), (exposition, nc, exposition...</td>\n",
       "      <td>[(Cette, det, ce), (exposition, nc, exposition...</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>annodis.er_00003</td>\n",
       "      <td>à peu près au même moment que Gutenberg invent...</td>\n",
       "      <td>[(à, prep, à), (peu, adv, peu), (près, adv, pr...</td>\n",
       "      <td>[(à, à), (peu, peu), (près, près), (au, au), (...</td>\n",
       "      <td>[(à, prep, à), (peu, adv, peu), (près, adv, pr...</td>\n",
       "      <td>[(à, prep, à), (peu, adv, peu), (près, adv, pr...</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>annodis.er_00004</td>\n",
       "      <td>Ensuite, fut installée une autre forge à la Va...</td>\n",
       "      <td>[(Ensuite, adv, ensuite), (,, ponct, ,), (fut,...</td>\n",
       "      <td>[(Ensuite, ensuite), (,, ,), (fut, être), (ins...</td>\n",
       "      <td>[(Ensuite, adv, ensuite), (,, nc, ,), (fut, v,...</td>\n",
       "      <td>[(Ensuite, adv, ensuite), (,, ponct, ,), (fut,...</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>annodis.er_00005</td>\n",
       "      <td>En 1953, les hauts fourneaux et fonderies de C...</td>\n",
       "      <td>[(En, prep, en), (1953, nc, 1953), (,, ponct, ...</td>\n",
       "      <td>[(En, en), (1953, 1953), (,, ,), (les, le), (h...</td>\n",
       "      <td>[(En, prep, en), (1953, nc, 1953), (,, nc, ,),...</td>\n",
       "      <td>[(En, prep, en), (1953, nc, 1953), (,, ponct, ...</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            sent_id                                               sent  \\\n",
       "0  annodis.er_00001                                          Gutenberg   \n",
       "1  annodis.er_00002  Cette exposition nous apprend que dès le XIIe ...   \n",
       "2  annodis.er_00003  à peu près au même moment que Gutenberg invent...   \n",
       "3  annodis.er_00004  Ensuite, fut installée une autre forge à la Va...   \n",
       "4  annodis.er_00005  En 1953, les hauts fourneaux et fonderies de C...   \n",
       "\n",
       "                                             sequoia  \\\n",
       "0                      [(Gutenberg, npp, gutenberg)]   \n",
       "1  [(Cette, det, ce), (exposition, nc, exposition...   \n",
       "2  [(à, prep, à), (peu, adv, peu), (près, adv, pr...   \n",
       "3  [(Ensuite, adv, ensuite), (,, ponct, ,), (fut,...   \n",
       "4  [(En, prep, en), (1953, nc, 1953), (,, ponct, ...   \n",
       "\n",
       "                                          treetagger  \\\n",
       "0                           [(Gutenberg, gutenberg)]   \n",
       "1  [(Cette, ce), (exposition, exposition), (nous,...   \n",
       "2  [(à, à), (peu, peu), (près, près), (au, au), (...   \n",
       "3  [(Ensuite, ensuite), (,, ,), (fut, être), (ins...   \n",
       "4  [(En, en), (1953, 1953), (,, ,), (les, le), (h...   \n",
       "\n",
       "                       frenchpreprocessing_camemBERT  \\\n",
       "0                      [(Gutenberg, npp, gutenberg)]   \n",
       "1  [(Cette, det, ce), (exposition, nc, exposition...   \n",
       "2  [(à, prep, à), (peu, adv, peu), (près, adv, pr...   \n",
       "3  [(Ensuite, adv, ensuite), (,, nc, ,), (fut, v,...   \n",
       "4  [(En, prep, en), (1953, nc, 1953), (,, nc, ,),...   \n",
       "\n",
       "                        frenchpreprocessing_stanford  sequoia_nb_tokens  \n",
       "0                      [(Gutenberg, npp, gutenberg)]                  1  \n",
       "1  [(Cette, det, ce), (exposition, nc, exposition...                 22  \n",
       "2  [(à, prep, à), (peu, adv, peu), (près, adv, pr...                 30  \n",
       "3  [(Ensuite, adv, ensuite), (,, ponct, ,), (fut,...                 19  \n",
       "4  [(En, prep, en), (1953, nc, 1953), (,, ponct, ...                 62  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Temps d'execution des outils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temps de chargement de l'outil TreeTagger : 0.005977630615234375\n",
      "\n",
      "Temps d'execution de l'opération pour TreeTagger : 10.856043577194214\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# readlines function \n",
    "file = open(\"./data/time_treetagger.txt\",\"r+\") \n",
    "l = file.readlines()\n",
    "for e in l:\n",
    "    print(e)\n",
    "file.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temps de chargement de l'outil FrenchPreprocessing (StanfordPOSTagger) : 5.900420665740967\n",
      "\n",
      "Temps d'execution de l'opération pour FrenchPreprocessing (StanfordPOSTagger) : 1734.35395693779\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# readlines function \n",
    "file = open(\"./data/time_stanford.txt\",\"r+\") \n",
    "l = file.readlines()\n",
    "for e in l:\n",
    "    print(e)\n",
    "file.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temps de chargement de l'outil FrenchPreprocessing (camemBERT) : 10.079216241836548\n",
      "\n",
      "Temps d'execution de l'opération pour FrenchPreprocessing (camemBERT) : 328.23137068748474\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# readlines function \n",
    "file = open(\"./data/time_camembert.txt\",\"r+\") \n",
    "l = file.readlines()\n",
    "for e in l:\n",
    "    print(e)\n",
    "file.close() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Réduction du dataset\n",
    "\n",
    "On ne conserve que les phrases pour lesquelles la tokenisation est identique entre sequoia, les FrenchPreprocessing et TreeTagger pour avoir exactement les mêmes phrases étudiées. On sélectionne donc 2492 phrases pour un total de 50654 tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction testant l'égalité entre les tokens effectués entre deux colonnes\n",
    "def tokens_equals(x,y):\n",
    "    if len(x)==len(y):\n",
    "        ind = True\n",
    "        for i in range(len(x)):\n",
    "            if x[i][0]!=y[i][0]:\n",
    "                ind = False\n",
    "                break\n",
    "    else:\n",
    "        ind = False\n",
    "    return ind\n",
    "\n",
    "# Colonnes indiquant l'égalité entre deux tokenisation\n",
    "df['sequoia_frenchpreprocessing_stanford_tokens_equals'] = df.apply(lambda x: tokens_equals(x['sequoia'],x['frenchpreprocessing_stanford']), axis = 1)\n",
    "df['sequoia_frenchpreprocessing_camemBERT_tokens_equals'] = df.apply(lambda x: tokens_equals(x['sequoia'],x['frenchpreprocessing_camemBERT']), axis = 1)\n",
    "df['sequoia_treetagger_tokens_equals'] = df.apply(lambda x: tokens_equals(x['sequoia'],x['treetagger']), axis = 1)\n",
    "df['sequoia_frenchpreprocessing_treetagger_tokens_equals'] = df['sequoia_treetagger_tokens_equals']&df['sequoia_frenchpreprocessing_stanford_tokens_equals']&df['sequoia_frenchpreprocessing_camemBERT_tokens_equals']==True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de phrases tokenisé de la même manière que dans le dataset Sequoia avec le FrenchPreprocessing : 2630\n",
      "Nombre de phrases tokenisé de la même manière que dans le dataset Sequoia avec le FrenchPreprocessing : 2630\n",
      "Nombre de phrases tokenisé de la même manière que dans le dataset Sequoia avec le TreeTagger : 2600\n",
      "Nombre de phrases tokenisé de la même manière que dans le dataset Sequoia avec les FrenchPreprocessing et le TreeTagger : 2492\n"
     ]
    }
   ],
   "source": [
    "print(\"Nombre de phrases tokenisé de la même manière que dans le dataset Sequoia avec le FrenchPreprocessing :\", df[df['sequoia_frenchpreprocessing_stanford_tokens_equals']==True]['sequoia_frenchpreprocessing_stanford_tokens_equals'].count())\n",
    "print(\"Nombre de phrases tokenisé de la même manière que dans le dataset Sequoia avec le FrenchPreprocessing :\", df[df['sequoia_frenchpreprocessing_camemBERT_tokens_equals']==True]['sequoia_frenchpreprocessing_camemBERT_tokens_equals'].count())\n",
    "print(\"Nombre de phrases tokenisé de la même manière que dans le dataset Sequoia avec le TreeTagger :\", df[df['sequoia_treetagger_tokens_equals']==True]['sequoia_treetagger_tokens_equals'].count())\n",
    "print(\"Nombre de phrases tokenisé de la même manière que dans le dataset Sequoia avec les FrenchPreprocessing et le TreeTagger :\", df[df['sequoia_frenchpreprocessing_treetagger_tokens_equals']==True]['sequoia_frenchpreprocessing_treetagger_tokens_equals'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de phrases sélectionnées pour l'étude : 2492\n",
      "Nombre de tokens sélectionnés pour l'étude : 50654\n"
     ]
    }
   ],
   "source": [
    "# On crée un nouveau dataset avec seulement les phrases ayant la même tokenisation\n",
    "df_equal = df[df['sequoia_frenchpreprocessing_treetagger_tokens_equals'] == True]\n",
    "df_equal.reset_index(inplace = True)\n",
    "print(\"Nombre de phrases sélectionnées pour l'étude :\", df_equal['sent_id'].count())\n",
    "print(\"Nombre de tokens sélectionnés pour l'étude :\", df_equal['sequoia_nb_tokens'].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exemple de lemmatisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequoia :\n",
      "le pose de un panneau stop paraître être le formule le mieux adapté pour assurer le sécurité de usager .\n",
      "TreeTagger :\n",
      "le pose de un panneau stop paraître être le formule le mieux adapter pour assurer le sécurité du usager .\n",
      "FrenchPreprocessing (StanfordPOSTagger) :\n",
      "le pose de un panneau stop paraître être le formule le mieux adapté pour assurer le sécurité des usager .\n",
      "FrenchPreprocessing (camemBERT) :\n",
      "le pose de un panneau stop paraître être le formule le mieux adapter pour assurer le sécurité des usager .\n"
     ]
    }
   ],
   "source": [
    "i = 6\n",
    "n = len(df_equal['sequoia'][i])\n",
    "\n",
    "l_sequoia = []\n",
    "l_treetagger = []\n",
    "l_frenchpreprocessing_camemBERT = []\n",
    "l_frenchpreprocessing_stanford = []\n",
    "\n",
    "for k in range(n):\n",
    "    l_sequoia.append(df_equal['sequoia'][i][k][2])\n",
    "    l_treetagger.append(df_equal['treetagger'][i][k][1])\n",
    "    l_frenchpreprocessing_camemBERT.append(df_equal['frenchpreprocessing_camemBERT'][i][k][2])\n",
    "    l_frenchpreprocessing_stanford.append(df_equal['frenchpreprocessing_stanford'][i][k][2])\n",
    "\n",
    "print(\"Sequoia :\")\n",
    "print(\" \".join(l_sequoia))\n",
    "\n",
    "print(\"TreeTagger :\")\n",
    "print(\" \".join(l_treetagger))\n",
    "\n",
    "print(\"FrenchPreprocessing (StanfordPOSTagger) :\")\n",
    "print(\" \".join(l_frenchpreprocessing_stanford))\n",
    "\n",
    "print(\"FrenchPreprocessing (camemBERT) :\")\n",
    "print(\" \".join(l_frenchpreprocessing_camemBERT))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance de la lemmatisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Récupération des doublets (mot,lemme) labélisés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_lemma(x):\n",
    "    l = []\n",
    "    for e in x:\n",
    "        l.append((e[0],e[2]))\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_equal['sequoia_word_lemma'] = df_equal['sequoia'].map(lambda x: word_lemma(x))\n",
    "df_equal['frenchpreprocessing_stanford_word_lemma'] = df_equal['frenchpreprocessing_stanford'].map(lambda x: word_lemma(x))\n",
    "df_equal['frenchpreprocessing_camemBERT_word_lemma'] = df_equal['frenchpreprocessing_camemBERT'].map(lambda x: word_lemma(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_sequoia(x,y):\n",
    "    cp = 0\n",
    "    for i in range(len(x)):\n",
    "        if x[i][1] == y[i][1]:\n",
    "                cp += 1\n",
    "    return cp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calcul du nombre de doublets (mot,lemme) identiques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_equal['sequoia_frenchpreprocessing_stanford_word_lemma'] = df_equal.apply(lambda x: compare_sequoia(x['sequoia_word_lemma'],x['frenchpreprocessing_stanford_word_lemma']), axis = 1)\n",
    "df_equal['sequoia_frenchpreprocessing_camemBERT_word_lemma'] = df_equal.apply(lambda x: compare_sequoia(x['sequoia_word_lemma'],x['frenchpreprocessing_camemBERT_word_lemma']), axis = 1) \n",
    "df_equal['sequoia_treetagger_word_lemma'] = df_equal.apply(lambda x: compare_sequoia(x['sequoia_word_lemma'],x['treetagger']), axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Affichage des pourcentages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pourcentage de doublets (mot,lemme) identiques entre les labélisations de sequoia et TreeTagger : 92.88%\n",
      "Pourcentage de doublets (mot,lemme) identiques entre les labélisations de sequoia et FrenchPreprocessing (StanfordPOSTagger) : 92.85%\n",
      "Pourcentage de doublets (mot,lemme) identiques entre les labélisations de sequoia et FrenchPreprocessing (camemBERT) : 93.12%\n"
     ]
    }
   ],
   "source": [
    "nb = df_equal['sequoia_treetagger_word_lemma'].sum()/df_equal['sequoia_nb_tokens'].sum()\n",
    "print(\"Pourcentage de doublets (mot,lemme) identiques entre les labélisations de sequoia et TreeTagger : \"+\"{:.2%}\".format(nb))\n",
    "\n",
    "nb = df_equal['sequoia_frenchpreprocessing_stanford_word_lemma'].sum()/df_equal['sequoia_nb_tokens'].sum()\n",
    "print(\"Pourcentage de doublets (mot,lemme) identiques entre les labélisations de sequoia et FrenchPreprocessing (StanfordPOSTagger) : \"+\"{:.2%}\".format(nb))\n",
    "\n",
    "nb = df_equal['sequoia_frenchpreprocessing_camemBERT_word_lemma'].sum()/df_equal['sequoia_nb_tokens'].sum()\n",
    "print(\"Pourcentage de doublets (mot,lemme) identiques entre les labélisations de sequoia et FrenchPreprocessing (camemBERT) : \"+\"{:.2%}\".format(nb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'outil FrenchPreprocessing (camemBERT) est beaucoup plus lent que TreeTagger, mais il peut servir pour de faibles volumes de données, ou bien pour du traitement en continu. Il est cependant légèrement plus performant (93.12% contre 92.88%).\n",
    "\n",
    "**Attention :** Le StanfordPOSTagger résiste mieux lorsque la séquence donnée est plus longue qu'une phrase. FrenchPreprocessing (camemBERT) mets environ 0,1 seconde par phrase pour la lemmatisation contre 0,7 seconde pour celui avec le StanfordPOSTagger, mais camemBERT est un modèle à complexité temporelle quadratique sur la longueur de la séquence donnée. Il est donc préférable, pour lemmatiser du texte, de découper celui-ci par phrases avant de le lemmatiser. Ensuite, il faudrait paralléliser les calculs réalisés par FrenchPreprocessing, car cela permettrait de diviser le temps d'execution par le nombre de coeurs du processeur utilisé. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
